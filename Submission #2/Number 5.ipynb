{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a41f57-eecc-4c43-a667-2303d947a789",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data partitioning completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Path to the folder containing the PNG images\n",
    "folder_path = '/Users/user/Downloads/pneumonia'\n",
    "\n",
    "# List all files in the folder, filtering out directories\n",
    "file_names = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "# Shuffle the list of file names randomly\n",
    "random.shuffle(file_names)\n",
    "\n",
    "# Calculate the number of files for training (80%) and testing (20%)\n",
    "num_train = int(0.8 * len(file_names))\n",
    "num_test = len(file_names) - num_train\n",
    "\n",
    "# Create directories for training and testing data\n",
    "train_dir = '/Users/user/Downloads/pneumonia/train'\n",
    "test_dir = '/Users/user/Downloads/pneumonia/test'\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Copy 80% of the files to the training directory\n",
    "for file_name in file_names[:num_train]:\n",
    "    src_path = os.path.join(folder_path, file_name)\n",
    "    dst_path = os.path.join(train_dir, file_name)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Copy 20% of the files to the testing directory\n",
    "for file_name in file_names[num_train:]:\n",
    "    src_path = os.path.join(folder_path, file_name)\n",
    "    dst_path = os.path.join(test_dir, file_name)\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "print(\"Data partitioning completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f2be84-d349-47ba-a9f5-599920256ca4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise applied to training and test sets.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def add_poisson(img, lambda_val):\n",
    "    poisson_noise = np.random.poisson(lambda_val, size=img.shape)\n",
    "    noisy_image = img + poisson_noise\n",
    "    noisy_image = np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "# Function to apply noise to images in a folder\n",
    "def apply_noise_to_folder(folder_path, output_folder, noise_type, noise_params):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.png'):\n",
    "            img_path = os.path.join(folder_path, file_name)\n",
    "            img = cv2.imread(img_path, 0)\n",
    "            for param in noise_params:\n",
    "                noisy_img = None\n",
    "                if noise_type == 'poisson':\n",
    "                    noisy_img = add_poisson(img.copy(), param)\n",
    "                output_subfolder = os.path.join(output_folder, str(param))\n",
    "                os.makedirs(output_subfolder, exist_ok=True)\n",
    "                output_path = os.path.join(output_subfolder, file_name)\n",
    "                cv2.imwrite(output_path, noisy_img)\n",
    "\n",
    "# Path to the training and test folders\n",
    "train_folder = '/Users/user/Downloads/pneumonia/train'\n",
    "test_folder = '/Users/user/Downloads/pneumonia/test'\n",
    "\n",
    "# Output folders for noisy training and test sets\n",
    "noisy_train_folder = '/Users/user/Downloads/pneumonia/noisy_train'\n",
    "noisy_test_folder = '/Users/user/Downloads/pneumonia/noisy_test'\n",
    "\n",
    "# Lambda values for Poisson noise\n",
    "lambda_values = [25, 50, 75]\n",
    "\n",
    "# Apply noise to training and test sets\n",
    "apply_noise_to_folder(train_folder, noisy_train_folder, 'poisson', lambda_values)\n",
    "apply_noise_to_folder(test_folder, noisy_test_folder, 'poisson', lambda_values)\n",
    "\n",
    "print(\"Noise applied to training and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9754900b-fd2f-4ff5-9ae1-ebf261b8f112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lambda = 25\n",
      "Average error for Median Filter: 0.08965595066547394\n",
      "Average error for Mean Filter: 0.08960691094398499\n",
      "Average error for Bilateral Filter: 0.08928577601909637\n",
      "Average error for Gaussian Filter: 0.0896238386631012\n",
      "\n",
      "Lambda = 50\n",
      "Average error for Median Filter: 0.08965595066547394\n",
      "Average error for Mean Filter: 0.08960691094398499\n",
      "Average error for Bilateral Filter: 0.08928577601909637\n",
      "Average error for Gaussian Filter: 0.0896238386631012\n",
      "\n",
      "Lambda = 75\n",
      "Average error for Median Filter: 0.08965595066547394\n",
      "Average error for Mean Filter: 0.08960691094398499\n",
      "Average error for Bilateral Filter: 0.08928577601909637\n",
      "Average error for Gaussian Filter: 0.0896238386631012\n",
      "\n",
      "Lambda = 25\n",
      "Average PSNR for Median Filter (lambda = 25): 10.901243109658 dB\n",
      "Average PSNR for Mean Filter (lambda = 25): 10.9046997008307 dB\n",
      "Average PSNR for Bilateral Filter (lambda = 25): 10.922254519204891 dB\n",
      "Average PSNR for Gaussian Filter (lambda = 25): 10.90364058155884 dB\n",
      "\n",
      "Lambda = 50\n",
      "Average PSNR for Median Filter (lambda = 50): 10.901243109658 dB\n",
      "Average PSNR for Mean Filter (lambda = 50): 10.9046997008307 dB\n",
      "Average PSNR for Bilateral Filter (lambda = 50): 10.922254519204891 dB\n",
      "Average PSNR for Gaussian Filter (lambda = 50): 10.90364058155884 dB\n",
      "\n",
      "Lambda = 75\n",
      "Average PSNR for Median Filter (lambda = 75): 10.901243109658 dB\n",
      "Average PSNR for Mean Filter (lambda = 75): 10.9046997008307 dB\n",
      "Average PSNR for Bilateral Filter (lambda = 75): 10.922254519204891 dB\n",
      "Average PSNR for Gaussian Filter (lambda = 75): 10.90364058155884 dB\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths to folders\n",
    "train_folder = '/Users/user/Downloads/pneumonia/train'\n",
    "test_folder = '/Users/user/Downloads/pneumonia/test'\n",
    "noisy_train_folder = '/Users/user/Downloads/pneumonia/noisy_train/25'\n",
    "noisy_test_folder = '/Users/user/Downloads/pneumonia/noisy_test/25'\n",
    "\n",
    "# Function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "# Load clean and noisy images for training and testing\n",
    "def load_data(train_folder, noisy_train_folder, test_folder, noisy_test_folder):\n",
    "    clean_train_images = load_images_from_folder(train_folder)\n",
    "    clean_test_images = load_images_from_folder(test_folder)\n",
    "    noisy_train_images = load_images_from_folder(noisy_train_folder)\n",
    "    noisy_test_images = load_images_from_folder(noisy_test_folder)\n",
    "    return clean_train_images, clean_test_images, noisy_train_images, noisy_test_images\n",
    "\n",
    "# Normalize the images\n",
    "def normalize_images(images):\n",
    "    normalized_images = []\n",
    "    for image in images:\n",
    "        if image.shape[-1] == 1:\n",
    "            normalized_image = np.squeeze(image, axis=-1)  # Remove singleton dimension\n",
    "        else:\n",
    "            normalized_image = image.astype('float32') / 255.\n",
    "        normalized_images.append(normalized_image)\n",
    "    return normalized_images\n",
    "\n",
    "# Load data\n",
    "clean_train_images, clean_test_images, noisy_train_images, noisy_test_images = load_data(train_folder, noisy_train_folder, test_folder, noisy_test_folder)\n",
    "\n",
    "# Normalize images\n",
    "clean_train_images = normalize_images(clean_train_images)\n",
    "clean_test_images = normalize_images(clean_test_images)\n",
    "noisy_train_images = normalize_images(noisy_train_images)\n",
    "noisy_test_images = normalize_images(noisy_test_images)\n",
    "\n",
    "# Function to apply median filter\n",
    "def apply_median_filter(image, kernel_size):\n",
    "    return cv2.medianBlur(image, kernel_size)\n",
    "\n",
    "# Function to apply mean filter\n",
    "def apply_mean_filter(image, kernel_size):\n",
    "    return cv2.blur(image, (kernel_size, kernel_size))\n",
    "\n",
    "# Function to apply bilateral filter\n",
    "def apply_bilateral_filter(image, d, sigma_color, sigma_space):\n",
    "    return cv2.bilateralFilter(image, d, sigma_color, sigma_space)\n",
    "\n",
    "# Function to apply Gaussian filter\n",
    "def apply_gaussian_filter(image, kernel_size):\n",
    "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "# Step 2: Apply denoising methods to noisy test images for each lambda value\n",
    "def denoise_images(noisy_images, method, kernel_size=None, d=None, sigma_color=None, sigma_space=None):\n",
    "    denoised_images = []\n",
    "    for img in noisy_images:\n",
    "        if method == 'median':\n",
    "            denoised_img = apply_median_filter(img, kernel_size)\n",
    "        elif method == 'mean':\n",
    "            denoised_img = apply_mean_filter(img, kernel_size)\n",
    "        elif method == 'bilateral':\n",
    "            denoised_img = apply_bilateral_filter(img, d, sigma_color, sigma_space)\n",
    "        elif method == 'gaussian':\n",
    "            denoised_img = apply_gaussian_filter(img, kernel_size)\n",
    "        \n",
    "        # Resize the denoised image to match the dimensions of the clean image\n",
    "        denoised_img_resized = cv2.resize(denoised_img, (clean_test_images[0].shape[1], clean_test_images[0].shape[0]))\n",
    "        \n",
    "        denoised_images.append(denoised_img_resized)\n",
    "    return denoised_images\n",
    "\n",
    "# Step 3: Calculate error metric for classical methods\n",
    "def calculate_error_for_classical_method(denoised_images, clean_test_images):\n",
    "    errors = []\n",
    "    for denoised_img, clean_img in zip(denoised_images, clean_test_images):\n",
    "        # Resize denoised_img to match the shape of clean_img\n",
    "        denoised_img_resized = cv2.resize(denoised_img, (clean_img.shape[1], clean_img.shape[0]))\n",
    "\n",
    "        # Calculate error\n",
    "        error = np.mean(np.square(clean_img - denoised_img_resized))\n",
    "        errors.append(error)\n",
    "    return errors\n",
    "\n",
    "\n",
    "# Step 4: Calculate error metric for CNN autoencoder (already implemented)\n",
    "\n",
    "# Step 5: Compare error metrics for different filters and lambda values\n",
    "lambda_values = [25, 50, 75]\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    print(f\"\\nLambda = {lambda_val}\")\n",
    "\n",
    "    # Denoise with Median Filter\n",
    "    if noisy_test_images:\n",
    "        denoised_images_median = denoise_images(noisy_test_images, 'median', kernel_size=3)\n",
    "        errors_median = calculate_error_for_classical_method(denoised_images_median, clean_test_images)\n",
    "        print(f\"Average error for Median Filter: {np.mean(errors_median)}\")\n",
    "\n",
    "    # Denoise with Mean Filter\n",
    "    denoised_images_mean = denoise_images(noisy_test_images, 'mean', kernel_size=3)\n",
    "    errors_mean = calculate_error_for_classical_method(denoised_images_mean, clean_test_images)\n",
    "    print(f\"Average error for Mean Filter: {np.mean(errors_mean)}\")\n",
    "\n",
    "    # Denoise with Bilateral Filter\n",
    "    denoised_images_bilateral = denoise_images(noisy_test_images, 'bilateral', d=9, sigma_color=75, sigma_space=75)\n",
    "    errors_bilateral = calculate_error_for_classical_method(denoised_images_bilateral, clean_test_images)\n",
    "    print(f\"Average error for Bilateral Filter: {np.mean(errors_bilateral)}\")\n",
    "\n",
    "    # Denoise with Gaussian Filter\n",
    "    denoised_images_gaussian = denoise_images(noisy_test_images, 'gaussian', kernel_size=3)\n",
    "    errors_gaussian = calculate_error_for_classical_method(denoised_images_gaussian, clean_test_images)\n",
    "    print(f\"Average error for Gaussian Filter: {np.mean(errors_gaussian)}\")\n",
    "\n",
    "def calculate_psnr_for_classical_method(denoised_images, clean_test_images):\n",
    "    psnrs = []\n",
    "    for denoised_img, clean_img in zip(denoised_images, clean_test_images):\n",
    "        # Resize the denoised image to match the dimensions of the clean image\n",
    "        denoised_img_resized = cv2.resize(denoised_img, (clean_img.shape[1], clean_img.shape[0]))\n",
    "\n",
    "        mse = np.mean(np.square(clean_img - denoised_img_resized))\n",
    "        if mse == 0:\n",
    "            psnr = 100  # PSNR is infinite when MSE is zero\n",
    "        else:\n",
    "            max_pixel = 1.0  # Assuming pixel values are in the range [0, 1]\n",
    "            psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "        psnrs.append(psnr)\n",
    "    return psnrs\n",
    "\n",
    "\n",
    "# Define lambda values\n",
    "lambda_values = [25, 50, 75]\n",
    "\n",
    "# Iterate over lambda values\n",
    "for lambda_val in lambda_values:\n",
    "    print(f\"\\nLambda = {lambda_val}\")\n",
    "    \n",
    "    # Denoise images using different filters\n",
    "    denoised_images_median = denoise_images(noisy_test_images, 'median', kernel_size=3)\n",
    "    denoised_images_mean = denoise_images(noisy_test_images, 'mean', kernel_size=3)\n",
    "    denoised_images_bilateral = denoise_images(noisy_test_images, 'bilateral', d=9, sigma_color=75, sigma_space=75)\n",
    "    denoised_images_gaussian = denoise_images(noisy_test_images, 'gaussian', kernel_size=3)\n",
    "    \n",
    "    # Calculate PSNR for each method\n",
    "    psnrs_median = calculate_psnr_for_classical_method(denoised_images_median, clean_test_images)\n",
    "    psnrs_mean = calculate_psnr_for_classical_method(denoised_images_mean, clean_test_images)\n",
    "    psnrs_bilateral = calculate_psnr_for_classical_method(denoised_images_bilateral, clean_test_images)\n",
    "    psnrs_gaussian = calculate_psnr_for_classical_method(denoised_images_gaussian, clean_test_images)\n",
    "    \n",
    "    # Print and compare PSNRs\n",
    "    print(f\"Average PSNR for Median Filter (lambda = {lambda_val}): {np.mean(psnrs_median)} dB\")\n",
    "    print(f\"Average PSNR for Mean Filter (lambda = {lambda_val}): {np.mean(psnrs_mean)} dB\")\n",
    "    print(f\"Average PSNR for Bilateral Filter (lambda = {lambda_val}): {np.mean(psnrs_bilateral)} dB\")\n",
    "    print(f\"Average PSNR for Gaussian Filter (lambda = {lambda_val}): {np.mean(psnrs_gaussian)} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e15b00-f328-4333-9f78-2baaef854196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
